# HTTP
* 기본적으로 HTTP는 앞서 설명한 전송 계층 위에 있는 애플리케이션 계층으로서 웹 서비스 통신에 사용된다. HTTP/1.0부터 시작해서 발전을 거듭하여 지금은 HTTP/3이 되었다.

## HTTP/1.0

HTTP/1.0은 기본적으로 한 연결당 하나의 요청을 처리하도록 설계되었다. 서버로부터 파일을 가져올 때마다 TCP의 3-웨이 핸드세이크를 계속해서 열어야 하기 때문에 RTT가 증가하는 단점이 있다.
* RTT : 패킷이 목적지에 도달하고 나서 다시 출발지로 돌아오기까지 걸리는 시간(패킷 왕복시간)

### RTT의 증가를 해결하기 위한 방법
매번 연결할 때마다 RTT가 증가하니 서버에 부담이 많이 가고 사용자 응답 시간이 길어졌다.
이를 해결하기 위해 이미지 스플리팅, 코드 압축, 이미지 Base64 인코딩을 사용하곤 했다.

#### 이미지 스플리팅
많은 이미지를 다운로드 받게 되면 과부하가 걸리기 때문에 많은 이미지가 합쳐 있는 하나의 이미지를 다운로드 받고, 이를 기반으로 background-image의 position을 이용하여 이미지를 표기하는 방법.

#### 코드 압축
코드 압축은 코드를 압축해서 개행 문자, 빈칸을 없애서 코드의 크기를 최소화하는 방법

#### 이미지 Base64인코딩
이미지 파일을 64진법으로 이루어진 문자열로 인코딩하는 방법. 
* 이 방법을 사용하면 서버와의 연결을 열고 이미지에 대해 서버에 HTTP 요청을 할 필요가 없다는 장점. 하지만 Base64 문자열로 변환할 경우 37% 정도 크기가 더 커지는 단점이 있다.
* 인코딩 : 정보의 형태나 형식을 표준화, 보안, 처리 속도 향상, 저장 공간 절약 등을 위해 다른 형태나 형식으로 변환하는 처리 방식

## HTTP/1.1
매번 TCP 연결을 하는 것이 아니라 한 번 TCP 초기화를 한 이후에 keep-alive라는 옵션으로 여러 개의 파일을 송수신할 수 있게 바뀌었습니다. 참고로 HTTP/1.0에서도 keep-alive가 있었지만 표준화가 되어 있지 않았고 HTTP/1.1부터 표준화가 되어 기본 옵션으로 설정되었다.

다음 그림처럼 한 번 TCP 3-웨이 핸드세이크가 발생하면 그다음부터 발생하지 않는다. 하지만 문서 안에 포함된 다수의 리소스(이미지,css파일,script파일)를 처리하려면 요청할 리소스개수에 비례해서 대기 시간이 길어지는 단점이 있다.

### HOL Blocking
HOL Blocking(Head Of Line Blocking)은 네트워크에서 같은 큐에 있는 패킷이 그 첫 번째 패킷에 의해 지연될 때 발생하는 성능 저하 현상을 말한다.

### 무거운 헤더 구조
HTTP/1.1의 헤더에는 쿠키 등 많은 메타데이터가 들어 있고 압축이 되지 않아 무거웠다.

## HTTP/2
HTTP/2는 SPDY 프로토콜에서 파생된 HTTP/1.x보다 지연 시간을 줄이고 응답 시간을 더 빠르게 할 수 있으며 멀티플렉싱, 헤더 압축, 서버 푸시, 요청의 우선순위 처리를 지원하는 프로토콜이다. 

### 멀티플렉싱
멀티플렉싱이란 여러 개의 스트림을 사용하여 송수신하는 것. 이를 통해 특정 스트림의 패킷이 손실되었다고 하더라도 해당 스트림에만 영향을 미치고 나머지 스트림은 멀쩡하게 동작할 수 있다. 
* 스트림: 시간이 지남에 따라 사용할 수 있게 되는 일련의 데이터 요소를 가리키는 데이터 흐름

이를 통해 단일 연결을 사용하여 병렬로 여러 요청을 받을 수 있고 응답을 줄 수 있다. 이렇게 되면 HTTP/1.x 에서 발생하는 문제인 HOL Blocking을 해결할 수 있다. 

### 헤더 압축
HTTP/1.x에는 크기가 큰 헤더라는 문제가 있었다.
이를 HTTP/2에서는 헤더 압축을 써서 해결하는데, 허프만 코딩 압축 알고리즘을 사용하는 HPACK 압축 형식을 가집니다.

#### 허프만 코딩
허프만 코딩은 문자열을 문자 단위로 쪼개 빈도수를 세어 빈도가 높은 정보는 적은 비트 수를 사용하여 표현하고, 빈도가 낮은 정보는 비트 수를 많이 사용하여 표현해서 전체 데이터의 표현에 필요한 비트양을 줄이는 원리입니다.

### 서버 푸시
HTTP/1.1에서는 클라이언트가 서버에 요청을 해야 파일을 다운로드받을 수 있었다면, HTTP/2는 클라이언트 요청 없이 서버가 바로 리소스를 푸시할 수 있다. html에는 css나 js파일이 포함되기 마련인데 html을 읽으면서 그 안에 들어 있던 css파일을 서버에서 푸시하여 클라이언트에 먼저 줄 수 있다.

## HTTPS
HTTP/2는 HTTPS 위에서 동작한다. HTTPS는 애플리케이션 계층과 전송 계층 사이에 신뢰 계층인 SSL/TLS 계층을 넣은 신뢰할 수 있는 HTTP 요청. 이를 통해 통신을 암호화한다.

### SSL/TLS
SSL(Secure Socket Layer)은 SSL 1.0부터 시작해서 SSL 2.0 SSL 3.0 TLS(Transport Layer Security Protocol) 1.0 TLS 1.3까지 버전이 올라가며 마지막으로 TLS로 명칭이 변경되었으나, 보통 이를 합쳐 SSL/TLS로 많이 부른다. 
SSL/TLS는 전송 계층에서 보안을 제공하는 프로토콜이다. 클라이언트와 서버와 통신 할때 SSL/TLS를 통해 제 3자가 메시지를 도청하거나 변조하지 못하도록 합니다.
앞의 그림처럼 SSL/TLS를 통해 공격자가 서버인 척하며 사용자 정보를 가로채는 네트워크 상의 인터셉터를 방지할 수 있다.
SSL/TLS는 보안 세션을 기반으로 데이터를 암호화하며 보안 세션이 만들어질 때 인증 메커니즘, 키 교환 암호화 알고리즘, 해싱 알고리즘이 사용됩니다.

#### 보안 세션
보안 세션이란 보안이 시작되고 끝나는 동안 유지되는 세션을 말하고, SSL/TLS는 핸드세이크를 통해 보안 세션을 생성하고 이를 기반으로 상태 정보 등을 공유한다.
세션 : 운영체제가 어떠한 사용자로부터 자신의 자산 이용을 허락하는 일정한 기간을 뜻한다. 즉, 사용자는 일정 시간 동안 응용 프로그램, 자원 등을 사용할 수 있다. 
클라이언트와 서버와 키를 공유하고 이를 기반으로 인증, 인증 확인 등의 작업이 일어나는 단 한번의 1-RTT가 생긴 후 데이터를 송수신하는 것을 볼 수 있다. 클라이언트에서 사이퍼 슈트를 서버에 전달하면 서버는 받은 사이퍼 슈트의 암호화 알고리즘 리스트를 제공할 수 있는지 확인한다. 제공할 수 있으면 서버에서 클라이언트로 인증서를 보내는 인증 메커니즘이 시작되고 이후 해싱 알고리즘 등으로 암호화된 데이터의 송수신이 시작된다.

사이퍼 슈트
사이퍼 슈트는 프로토콜, AEAD 사이퍼 모드, 해싱 알고리즘이 나열된 규약을 말하며 다섯개가 있다.
* TLS_AES_128_GCM_SHA256
* TLS_AES_256_GCM_SHA384
* TLS_CHACHA20_POLY1305_SHA256
* TLS_AES_128_CCM_SHA256
* TLS_AES_128_CCM_8_SHA256
예를 들어 TLS_AES_128_GCM_SHA256에는 세가지 규약이 들어 있는데 TLS는 프로토콜, AES_128_GCM은AEAD 사이퍼 모드, SHA256은 해싱 알고리즘을 뜻한다.

AEAD 사이퍼 모드
AEAD(Authenticated Encrption with Associated Data)는 데이터 암호화 알고리즘이며 AES_128_GCM 등이 있다. 예를 들어 AES_128_GCM이라는 것은 128비트의 키를 사용하는 표준 블록 암호화 기술과 병렬 계산에 용이한 암호화 알고리즘 GCM이 결합된 알고리즘을 뜻한다.

#### 인증 메커니즘
인증 메너키즘은 CA(Certificate Authorities)에서 발급한 인증서를 기반으로 이루어진다. CA에서 발급한 인증서는 안전한 연결을 시작하는 데 있어 필요한 공개키를 클라이언트에 제공하고 사용자가 접속한 서버가 신뢰 할 수 있는 서버임을 보장한다. 인증서는 서비스 정보, 공개키, 지문, 디지털 서명 등으로 이루어져 있다. 참고로 CA는 아무 기업이나 할 수 있는 것이 아니고 신뢰성이 엄격하게 공인된 기업들만 참여할 수 있으며 대표적인 기업으로는 Comodo, GoDaddy, GlobalSign, 아마존 등이 있다.

CA 발급 과정
자신의 서비스가 CA 인증서를 발급받으려면 자신의 사이트 정보와 공개키를 CA에 제출해야한다. 이후 CA는 공개키를 해시한 값인 지문(finger print)을 사용하는 CA의 비밀키 등을 기반으로 CA 인증서를 발급한다.
개인키 : 비밀키라고도 하며, 개인이 소유하고 있는 키이자 반드시 자신만이 소유해야 하는 키
공개키 : 공개되어 있는 키

#### 암호화 알고리즘
키 교환 암호화 알고리즘으로는 대수곡선 기반의 ECDHE(Elliptic Curve Diffie-Hellman Ephermeral) 또는 모듈식 기반의 DHE(Diffie-Hellman Ephermeral)를 사용한다. 둘다 디피-헬만(Diffie-Hellman) 방식을 근간으로 만들어졌다.

디피-헬만 키 교환 암호화 알고리즘
* 디피-헤람ㄴ 키 교환(Diffie-Hellman key exchange) 암호화 알고리즘은 암호키를 교환하는 하나의 방법이다.
* 처음에 공개 값을 공유하고 각자의 비밀값과 혼합한 후 혼합 값을 공유한다. 그다음 각자의 비밀 값과 또 혼합한다. 그 이후에 공통의 암호키가 생성되는 것. 이렇게 클라이언트와 서버 모두 개인키와 공개키를 생성하고 서로에게 공개키를 보내고 공개키와 개인키를 결합하여 PSK(사전 합의된 비밀키)가 생성된다면, 악의적인 공격자가 개인키 또는 공개키를 가지고도 PSK가 없기 때문에 아무것도 할 수 없다. 이를 통해 키를 암호화 할 수 있다.

#### 해싱 알고리즘
* 해싱 알고리즘은 데이터를 추정하기 힘든 더 작고, 섞여 있는 조각으로 만드는 알고리즘이다. SSL/TLS는 해싱 알고리즘으로 SHA-256 알고리즘과 SHA-384 알고리즘을 쓴다. 

SHA-256 알고리즘
해시 함수의 결괏값이 256비트인 알고리즘이며 비토 코인을 비롯한 많은 블록체인 시스템에서도 쓴다. SHA-256 알고리즘은 해싱을 해야 할 메시지에 1을 추가하는 등 전처리를 하고 전처리된 메시지를 기반으로 해시를 반환한다. 

해시: 다양한 길이를 가진 데이터를 고정된 길이를 가진 데이터로 매핑한 값
해싱: 임의의 데이터를 해시로 바꿔주는 일이며 해시 함수가 이를 담당
해시 함수: 임의의 데이터를 입력으로 받아 일정한 길이의 데이터로 바꿔주는 함수

참고로 TLS 1.3은 사용자가 이전에 방문한 사이트로 다시 방문한다면 SSL/TLS에서 보안세션을 만들 때 걸리는 통신을 하지 않아도 된다. 이를 0-RTT라고 한다.

### SEO에도 도움이 되는 HTTPS
구글은 SSL 인증서를 강조해왔고 사이트 내 모든 요소가 동일하다면 HTTPS 서비스를 하는 사이트가 그렇지 않은 사이트보다 SEO순위가 높을 것이라고 공식적으로 발혔다. 
SEO(Search Engine Optimization): 검색엔진 최적화를 뜻하며 사용자들이 구글, 네이버 같은 검색엔진으로 웹 사이트를 검색했을 때 그 결과를 페이지 상단에 노출시켜 많은 사람이 볼 수 있도록 최적화하는 방법

서비스를 운영한다면 SEO 관리는 필수이다. 내가 만든 사이트에 많은 사람이 유입되면 좋기 때문이다. 이를 위한 방법으로 캐노니컬 설정, 메타설정, 페이지 속도개선, 사이트맵 관리 등이 있다.

#### 캐노니컬 설정
[캐노니컬이란](https://growthacking.kr/%EC%BA%90%EB%85%B8%EB%8B%88%EC%BB%AC-%ED%83%9C%EA%B7%B8-canonical-tag%EB%A1%9C-%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84-%EC%B5%9C%EC%A0%81%ED%99%94%ED%95%98%EA%B8%B0/)

#### 메타설정
html 파일의 가장 윗부분인 메타를 잘 설정해야 한다.
메타 태그는 페이지의 콘텐츠를 설명하는 텍스트 스니펫이며, 페이지가 무엇을 설명하는지 검색엔진에게 알려주느 아주 중요한 태그이다. 일반적으로 \<head>에 있는 HTML에만 존재하므로 소스코드에서 확인이 가능하다. 

#### 페이지 속도 개선
사이트의 속도는 빨라야 한다. 
구글의 PageSpeedInsights로 가서 리포팅을 주기적으로 받으며 관리한다. [PageSpeedInsights](https://developers.google.com/speed/pagespeed/insights)

#### 사이트맵 관리
사이트맵(sitemap.xml)을 정기적으로 관리하는 것은 필수이다. 코드를 직접 작성하는 대신 사이트맵 생성 도구를 사용하여 생성하고 상시 자동 업데이트 하는 것이 좋다. 웹사이트 루트 디렉토리 밑에 위치시키는 것이 좋다. 

sitemap 파일은 검색 엔진 크롤링 로봇에게 웹 사이트에서 크롤링 해야 할 URL을 전달한다. 사이트 맵 파일은 해당 사이트의 url 모두를 xml 파일 형식으로 포함하는데 웹 사이트 운영자는 각 url과 추가 정보로서 이 url 콘텐츠의 최종 업데이트 시점 및 업데이트 빈도 url 대비 상대적인 중요도 정보를 여기에 담을 수 있다. 사이트 맵을 지원하는 검색 엔진은 이 정보를 사용하여 웹 사이트 크롤링을 보다 효율적으로 할 수 있게 된다.
웹사이트의 주요 인터페이스 즉 글로벌 네비게이션 바 등의 메뉴를 통해 바로 접근할 수 없는 웹 콘텐츠 등을 정의하고 크롤링 로봇이 바로 URL에 접근할 수 있게 한다.
```
  <? xml version = "1.0"encoding = "UTF-8"?>
<urlset
      xmlns = "http://www.sitemaps.org/schemas/sitemap/0.9"
      xmlns : xsi = "http://www.w3.org/2001/XMLSchema-instance"
      xsi : schemaLocation = "http://www.sitemaps.org/schemas/sitemap/0.9
      http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd ">
<URL>
  <loc> https://www.ascentkorea.com/search-engine-optimization/ </ loc>
  <priority> 1.00 </ priority>
  <changefreq> weekly </ changefreq>
</ url>
<URL>
  <loc> https://www.ascentkorea.com/search-data-research-content-marketing/ </ loc>
  <priority> 0.80 </ priority>
  <changefreq> weekly </ changefreq>
</ url>
<URL>
  <loc> https://www.ascentkorea.com/japan-marketing/ </ loc>
  <priority> 0.80 </ priority>
  <changefreq> weekly </ changefreq>
</ url>
<URL>
  <loc> https://www.ascentkorea.com/ascent-korea-official-blog-listeningmind/ </ loc>
  <priority> 0.80 </ priority>
  <changefreq> weekly </ changefreq>
</ url>
</ urlset>
```


* 로봇 텍스트 파일(robots.txt)과 사이트맵파일(sitemap.xml)은 사이트에 방문하는 검색엔진의 크롤러를 제어하기 위해 설정하는 파일이다. 이를 잘못 설정했을 경우 사이트 전체가 검색엔진에 의해 색인이 안되는 문제를 일이킬 정도로 중요한 SEO 관리 포인트이다. 
* Robots.txt : 검색의 크롤링 로봇이 웹에 접근할 때 로봇이 지켜야하는 규칙과 사이트맵 파일의 위치를 알려주는 역할을 하는 파일. robots.txt에 기록된 내용을 통해서 웹 사이트의 디렉토리 별로 크롤링을 할 수 있는지 없는지를 지정할 수 있는데 이 파일에 아무런 내용도 지정하지 않으면 검색엔진의 크롤링 로봇들은 웹사이트에서 확인할 수 있는 모든 콘텐츠를 색인하고 검색결과에 노출 시킨다.
	* 역할1 : 웹사이트 내의 특정 콘텐츠, 웹페이지, 서브폴더, 디렉토리로의 크롤러 접근 제어
	* 역할2 : 사이트맵 위치 전달
	* 역할3: 검색 크롤러에 의한 과부하 방지
* 주의점 : robots.txt파일은 모든 사람이 접근할 수 있기 때문에 보안 수단으로 사용해서는 안된다. 검색엔진 크롤링 로봇이 robots.txt 내용을 반드시 따르는 것은 아니다.
```
User-agent: *  
Disallow: /wp-admin/  
Allow: /wp-admin/admin-ajax.php  
Disallow: /user-profile/  
Disallow: /scripts/
Sitemap: http://www.ascentkorea.com/sitemap.xml
```

## HTTPS 구축 방법
HTTPS 구축 방법은 크게 세 가지다. 직접 CA에서 구매한 인증키를 기반으로 HTTPS 서비스를 구축하거나 서버 앞단의 HTTPS를 제공하는 로드밸런서를 두거나 서버 앞단에 HTTPS를 제공하는 CDN을 둬서 구축한다.

# HTTP/3
HTTP/3은 HTTP/1.1 및 HTTP/2와 함께 world wide web에서 정보를 교환하는데 사용되는 HTTP의 세번째 버전이다. TCP 위에서 돌아가는 HTTP/2와는 달리 HTTP/3는 QUIC이라는 계층 위에서 돌아가며, TCP 기반이 아닌 UDP 기반으로 돌아간다.
또한, HTTP/2에서 장점이었던 멀티플렉싱을 가지고 있으며 초기 연결 설정 시 지연시간 감소라는 장점이 있다.

## 초기 연겨 설정 시 지연시간 감소
QUIC은 TCP를 사용하지 않기 때문에 통신을 시작할 때 번거로운 3-웨이 핸드세이크 과정을 거치지 않아도 된다.
QUIC은 첫 연결 설정에 1-RTT만 소요딘다. 클라이언트가 서버에 어떤 신호를 한 번 주고, 서버도 거기에 응답하기만 하면 바로 본 통신을 시작할 수 있다. 참고로 QUIC은 순방향 오류 수정 메커니즘(FEC, Forward Error Correction)이 적용되었다. 이는 전송한 패킷이 손실되었다면 수신 측에서 에러를 검출하고 수정하는 방식이며 열악한 네트워크 환경에서도 낮은 패킷 손실률을 보인다.

Q. www.naver.com을 주소창에 입력하면 어떻게 될까?

→ 대기열, 캐싱, DNS, 라우팅, ARP, 초기연결을 거쳐 컨텐츠를 다운받게 되고 이 후 브라우저 렌더링 과정을 거쳐 네이버라는 화면이 나타나게 된다. 또한 이러한 과정이 비캡슐화, 캡슐화과정을 거쳐서 이뤄지게 된다.
  
대기열: 브라우저는 주소창입력에 대한 요청을 대기열에 넣는다. 이 때 HTTP/1.0및 HTTP/1.1의 경우 오리진당 6개의 병렬적인 TCP연결만을 허용하며 HTTP/2의 경우 스트링 등을 통해 HTTP1.x의 헤드라인 차단 등을 해결한다.
 
캐싱 : 캐싱은 요청된 값의 결과값을 저장하고 그 값을 다시 요청하면 다시 제공하는 기술, 이는 공유 프록시캐시와 브라우저 캐시로 나눠진다.

* 브라우저 캐시 : 브라우저 캐시는 쿠키, 로컬스토리지 등을 포함한 캐시. 브라우저 자체가 사용자가 HTTP를 통해 다운로드하는 모든 문서를 보유하는 것. 예를 들면 어떤 사이트를 갔다가 다시 방문하면 좀 더 빠르게 컨텐츠가 나타나는 데 그것이 브라우저 캐시이다. 인터넷 사용기록을 삭제하고 싶어서 누르면 쿠키 및 기타 사이트 데이터, 캐시 부분이다.

* 공유 프록시 캐시 : 공유 프록시 캐시는 요청한 서버에서 프록시서버가 캐싱하는 것을 말한다. 예를 들면 Node.js로 서버를 구축한다면 앞단의 프록시서버로 nginx 서버를 둬서 이 서버를 캐싱 서버로 사용할 수 있다.

  
DNS 조회: 브라우저가 요청의 IP 주소를 확인하는 단계이다. DNS는 도메인 이름과 IP 주소를 매핑해주는 서버이다. 예를 들어 www.naver.com 에 DNS 쿼리가 오면 Root DNS - .com DNS - .naver DNS - .www DNS 과정을 거쳐 완벽한 주소를 찾아 IP 주소를 매핑한다.
참고로 DNS로 요청을 전달하는 것은 아니고 먼저 컴퓨터 메모리에 있는 호스트 파일 등 캐시를 확인한 후 캐시미스가 일어나면 DNS서버로 요청한다.

DNS의 장점 : 이를 통해 IP주소가 바뀌어도 사용자들에게 똑같은 도메인 주소로 서비스할 수 있다. 예를 들어 www.naver.com IP주소가 222.111.222.111에서 2222.111.222.122로 바뀌어도 www.naver.com이라는 주소로 쓸 수 있다.

  
라우팅(홉바이홉 통신): IP주소를 찾아가는 과정인데, DNS에서 받은 IP 주소를 기반으로 해당 목적지까지 라우팅 테이블, 서브네트워크 등을 거쳐 IP 주소를 찾아가야 한다. 각각의 라우터에 있는 라우팅 테이블의 IP를 기반으로 패킷을 전달하고 다시 전달해나간다. 즉 통신 장치에 있는 라우팅 테이블의 IP를 통해 시작 주소부터 시작하여 다음 IP로 계쏙해서 이동하는 라우팅 과정을 거쳐 패킷이 최종 목적지까지 도달하는 통신.

라우팅 테이블: 라우팅 테이블은 송신지에서 수신지까지 도달하기 위해 사용되며 라우터에 들어가 있는 목적지 정보들과 그 목적지로 가기 위한 방법이 들어 있는 리스트를 뜻한다. 라우팅 테이블에는 게이트웨이와 모든 목적지에 대해 해당 목적지에 도달하기 위해 거쳐야 할 다음 라우터의 정보를 가지고 있다.

게이트웨이: 서로 다른 통신망, 프로토콜을 사용하는 네트워크 간의 통신을 가능하게 하는 관문 역할을 하는 컴퓨터나 소프트웨어를 두루 일컫는 용어.


ARP: 컴퓨터와 컴퓨터간의 통신은 흔히들 IP 주소 기반으로 통신한다고 알고 있지만 정확히 말하면 IP 주소에서 ARP를 통해 MAC 주소를 찾아 MAC 주소를 기반으로 통신한다. ARP(Address Resolition Protocol)란 IP주소로부터 MAC 주소를 구하는 IP와 MAC 주소의 다리 역할을 하는 프로토콜이다. ARP를 통해 가상 주소인 IP 주소를 실제 주소인 MAC 주소로 변환한다. 이와 반대로 RARP를 통해 실제 주소인 MAC주소를 가상 주소인 IP 주소로 변환하기도 한다.


초기 연결: 이제 브라우저가 TCP 3웨이-헨드세이크 및 SSL 연결등을 통해 연결을 설정한다. 이 후 요청을 보낸 후 드디어 해당 요청한 서버로부터 응답을 받는다.

  
콘텐츠다운로드: 브라우저는 서버로부터 응답을 수신한다.
  
브라우저렌더링: 받은 컨텐츠로부터 브라우저 렌더링이 일어난다.

- DOM 트리 구축: 하나의 html페이지는 div, span 등 각각 요소를 노드로 설정이 되어 트리 형태로 저장되는데 이를 DOM 트리라고 한다.

- 렌더트리와 렌더레이어 생성: 각각의 노드는 CSS 파서에 의해 정해진 스타일 규칙이 적용되어 있습니다. span.color="red"는 노드 색깔이 빨간색이다라는 규칙에 따라 CSSOM이라는 트리가 만들어지고 미리 만들어놓은 DOM 트리 내에 있는 노드와 함께 랜더객체가 생성되며 이들이 모여 병렬적인 렌더트리가 생성된다. 이때 display:none이 포함된 노드는 지워지고 font-size등 상속적인 스타일은 부모노드에만 위치하도록 설계하는 등 최적화를 거쳐 렌더레이어가 완성된다.

- 렌더레이어 대상으로 Layout 설정

- 렌더레이어 대상으로 paint

- 레이어 합치기 및 표기

이 후 화면이 나타나게 된다.

  
이 과정들이 캡슐화 과정과 비캡슐화 과정을 거쳐 송수신된다.

캡슐화 과정은 상위 계층의 헤더와 데이터를 하위 계층의 데이터 부분에 포함시키고 해당 계층의 헤더를 삽입하는 과정
![1](./http/%ED%99%94%EB%A9%B4%20%EC%BA%A1%EC%B2%98%202022-10-04%20131830.png)

비캡슐화 과정은 하위 계층에서 상위 계층으로 가며 계층의 헤더 부분을 제거하는 과정
![2](./http/%ED%99%94%EB%A9%B4%20%EC%BA%A1%EC%B2%98%202022-10-04%20131904.png)